{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDEHgNFEaK42JFXMuUKq7W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naidu1997/Natural-Language-Process/blob/main/Bag_Of_Words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjwZL0t6zwZS",
        "outputId": "c627e3e1-ec10-4335-a2cb-92200aa969d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "voabulary: ['.', 'are', 'beautiful', 'birds.the', 'drizzling.the', 'hot', 'is', 'looks', 'parrots', 'rain', 'sun', 'very']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#sample documents\n",
        "documents={\n",
        "    \"parrots are very beautiful birds.\"\n",
        "    \"the rain is drizzling.\"\n",
        "    \"the sun looks very hot.\"\n",
        "}\n",
        "\n",
        "#tokenize the documents (you may add more preprocessing steps like stemming or stop word removal)\n",
        "nltk.download('punkt')\n",
        "tokenized_documents=[nltk.word_tokenize(doc.lower())for doc in documents]\n",
        "#flatten the list of lists and remove duplicates to create a vocabulary\n",
        "vocabulary= sorted(set([word for doc in tokenized_documents for word in doc]))\n",
        "print(\"voabulary:\",vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step2: Building the vocabulary and vectorization\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n"
      ],
      "metadata": {
        "id": "NLtwfRbXBFoR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize countvectorizer\n",
        "vectorizer= CountVectorizer(vocabulary=vocabulary)\n",
        "#fit and transform the documents to create the bag of words model\n",
        "x= vectorizer.fit_transform(documents)\n",
        "#convert the result to an array for better readability\n",
        "bow_array= x.toarray()\n",
        "print(\"bag of words model:\\n\", bow_array)\n",
        "print(\"feature names:\\n\",vectorizer.get_feature_names_out())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jxWyPQy-N8a",
        "outputId": "7c604fe3-694a-4dc1-f295-3795b371110c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bag of words model:\n",
            " [[0 1 1 0 0 1 1 1 1 1 1 2]]\n",
            "feature names:\n",
            " ['.' 'are' 'beautiful' 'birds.the' 'drizzling.the' 'hot' 'is' 'looks'\n",
            " 'parrots' 'rain' 'sun' 'very']\n"
          ]
        }
      ]
    }
  ]
}